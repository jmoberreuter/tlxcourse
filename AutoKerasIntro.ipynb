{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start our journey in autokeras by investigating the classic MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "#from autokeras import ImageClassifier\n",
    "#from autokeras.constant import Constant\n",
    "from autokeras.image.image_supervised import ImageClassifier, load_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Directory: /var/folders/wz/_x09ytx52_q_ry_s7rcg8lg9lxbm17/T/autokeras_17KWSA\n",
      "Preprocessing the images.\n",
      "Preprocessing finished.\n",
      "\n",
      "Initializing search.\n",
      "Initialization finished.\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 0               |\n",
      "+----------------------------------------------+\n",
      "                                                                                                    \n",
      "No loss decrease after 5 epochs.\n",
      "\n",
      "\n",
      "Saving model.\n",
      "+--------------------------------------------------------------------------+\n",
      "|        Model ID        |          Loss          |      Metric Value      |\n",
      "+--------------------------------------------------------------------------+\n",
      "|           0            |  0.24423838332295417   |         0.9776         |\n",
      "+--------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "+----------------------------------------------+\n",
      "|               Training model 1               |\n",
      "+----------------------------------------------+\n",
      "Epoch-2, Current Metric - 0.982:  67%|████████████████        | 310/465 [44:03<22:40,  8.78s/ batch]Time is out.\n"
     ]
    }
   ],
   "source": [
    "clf = ImageClassifier(verbose=True, augment=False)\n",
    "clf.fit(x_train, y_train, time_limit=12 * 60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch-26, Current Metric - 0.9769:  68%|███████████████       | 320/469 [01:51<00:54,  2.73 batch/s]"
     ]
    }
   ],
   "source": [
    "clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)\n",
    "y = clf.evaluate(x_test, y_test)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's persist our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.export_autokeras_model('mnist_nn_classifier.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to load our model again at a later time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autokeras.utils import pickle_from_file\n",
    "model = pickle_from_file('mnist_nn_classifier.pkl')\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also vizualize the model with the help of graphviz (https://graphviz.gitlab.io/download/). To use this specify a path for the model before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ImageClassifier(path=\".\",verbose=True, augment=False) # Give a custom path of your choice\n",
    "clf.fit(x_train, y_train, time_limit=30 * 60)\n",
    "clf.final_fit(x_train, y_train, x_test, y_test, retrain=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General CNNsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was easy. Let's give autokeras something somewhat more challenging: the fashion MNIST dataset. This would in principle work the same but let's try to learn a more general Autokeras workflow. The CnnModule can generates neural architecture with basic cnn modules and the ResNet module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/fashion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autokeras import CnnModule\n",
    "from autokeras.nn.loss_function import classification_loss\n",
    "from autokeras.nn.metric import Accuracy\n",
    "\n",
    "TEST_FOLDER = \"test\"\n",
    "cnnModule = CnnModule(loss=classification_loss, metric=Accuracy, searcher_args={}, path=TEST_FOLDER, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that loss and metric determine the type of training model(classification or regression or others). \n",
    "The search_args can be chosen from the following:\n",
    "        - n_classes: Number of classes in the target classification task.\n",
    "        - input_shape: Arbitrary, although all dimensions in the input shaped must be fixed.\n",
    "            Use the keyword argument `input_shape` (tuple of integers, does not include the batch axis)\n",
    "            when using this layer as the first layer in a model.\n",
    "        - verbose: Verbosity mode.\n",
    "        - history: A list that stores the performance of model. Each element in it is a dictionary of 'model_id',\n",
    "            'loss', and 'metric_value'.\n",
    "        - neighbour_history: A list that stores the performance of neighbor of the best model.\n",
    "            Each element in it is a dictionary of 'model_id', 'loss', and 'metric_value'.\n",
    "        - path: A string. The path to the directory for saving the searcher.\n",
    "        - metric: An instance of the Metric subclasses.\n",
    "        - loss: A function taking two parameters, the predictions and the ground truth.\n",
    "        - generators: A list of generators used to initialize the search.\n",
    "        - model_count: An integer. the total number of neural networks in the current searcher.\n",
    "        - descriptors: A dictionary of all the neural network architectures searched.\n",
    "        - trainer_args: A dictionary. The params for the constructor of ModelTrainer.\n",
    "        - default_model_len: An integer. Number of convolutional layers in the initial architecture.\n",
    "        - default_model_width: An integer. The number of filters in each layer in the initial architecture.\n",
    "        - training_queue: A list of the generated architectures to be trained.\n",
    "        - x_queue: A list of trained architectures not updated to the gpr.\n",
    "        - y_queue: A list of trained architecture performances not updated to the gpr.\n",
    "   \n",
    "path is the path to store the whole searching process and generated model.\n",
    "verbose is a boolean. Setting it to true prints to stdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can search the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnModule.fit(n_output_node, input_shape, train_data, test_data, time_limit=24 * 60 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have\n",
    "* train_data: A DataLoader instance representing the training data. \n",
    "* test_data: A DataLoader instance representing the testing data. \n",
    "* trainer_args: A dictionary containing the parameters of the ModelTrainer constructor. \n",
    "* retrain: A boolean of whether reinitialize the weights of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other application:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to search for a neural network architecture for your structured dataset? You can also have autokeras search for the best Mulitlayer-Perceptron architecture. It works just the same. Hint: the corresponding module is called \"MlpModule\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Play with the time slots to see if you improve your results.\n",
    "2. Get yourself a training dataset with very little data and see if you can still get decent performance by having CnnModule to search for an architecture including transfer learning.\n",
    "3. Compare the modelling time and effort for creating an MNIST classifier in keras directly, without the use of Autokeras.\n",
    "4. Build an MLP with the corresponding module for the banking dataset. (You can later even evaluate it with the interpretability techniques, we have learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (talanx)",
   "language": "python",
   "name": "talanx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
